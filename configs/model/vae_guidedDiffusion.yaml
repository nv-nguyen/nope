_target_: src.model.base.PoseConditional
u_net:
  _target_: src.model.u_net.guided_diffusion.adapt_u_net.UNetModelPose
  attention_resolutions: 
  - 32
  - 16
  - 8
  channel_mult:
  - 1
  - 1
  - 2
  - 2
  - 4
  - 4 
  in_channels: 4
  out_channels: 4
  model_channels: 256
  image_size: 256
  num_head_channels: 64
  num_heads: 4
  num_heads_upsample: -1
  num_res_blocks: 2
  resblock_updown: true
  use_scale_shift_norm: true
  num_classes: 

  # pose parts
  rot_representation_dim: 6
  pose_mlp_name: "single_layer"
  encoder:
    _target_: src.model.encoder.AutoencoderKL.VAE_StableDiffusion
    pretrained_path: ${machine.root_dir}/pretrained/stable-diffusion-v1-5_vae.pth
    latent_dim: 4
    name: VAE
  
  pretrained_path: ${machine.root_dir}/pretrained/openai/256x256_diffusion.pt


save_dir: ${save_dir}
optim_config:
  loss_type: l1
  lr: 5e-5
  weight_decay: 0.0005
  warm_up_steps: 500
  use_inv_deltaR: true
testing_config:
  similarity_metric: l2 # cosine

checkpoint_path: